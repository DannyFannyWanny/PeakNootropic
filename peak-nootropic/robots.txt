User-agent: *
Allow: /

# Allow all search engines to crawl the entire site
# This is a simple robots.txt file for a static website

# Sitemap location (uncomment and update when you have a sitemap)
# Sitemap: https://yourdomain.com/sitemap.xml

# Disallow specific files or directories if needed
# Disallow: /admin/
# Disallow: /private/
# Disallow: /temp/

# Crawl delay (optional - in seconds)
# Crawl-delay: 1 